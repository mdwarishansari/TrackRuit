import re
from typing import Dict, List, Any
import logging
from .base_model import BaseModel
from pipelines.preprocess import preprocessor

# Set up logger
logger = logging.getLogger("ats_model")

class ATSModel(BaseModel):
    """ATS Compatibility Model for ML-powered resume analysis with calibrated scoring"""
    
    def __init__(self, version: str = None):
        super().__init__("ats", version)
        self._init_ml_components()
    
    def _init_ml_components(self):
        """Initialize ML-specific components"""
        # ML Feature: Section detection patterns
        self.section_patterns = {
            'experience': r'(experience|work history|employment|professional)',
            'education': r'(education|academic|qualifications|degree)',
            'skills': r'(skills|technical skills|competencies|proficiencies)'
        }
        
        # ML Feature: ATS scoring weights (calibrated for more realistic scores)
        self.weights = {
            'sections': 0.3,
            'length': 0.3,
            'contact': 0.2,
            'achievements': 0.2
        }
    
    def _create_default_model(self):
        """Create default ATS compatibility model"""
        self.is_loaded = True
        print(f"âœ… ATS Model v{self.get_version()} loaded with ML scoring")
    
    def preprocess(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ML Preprocessing: Clean and prepare resume data"""
        resume_text = data.get('resume_text', '')
        
        # ML Feature: Advanced text cleaning
        clean_text = self._advanced_clean(resume_text)
        
        return {
            'resume_text': clean_text,
            'original_text': resume_text,
            'original_data': data
        }
    
    def _advanced_clean(self, text: str) -> str:
        """ML Feature: Advanced text cleaning for resume analysis"""
        if not text:
            return ""
        
        # Convert to lowercase
        text = text.lower()
        
        # Remove URLs, emails, phone numbers
        text = re.sub(r'http\S+|www\S+|https\S+', '', text)
        text = re.sub(r'\S+@\S+', '', text)
        text = re.sub(r'[\+\(]?[1-9][0-9 .\-\(\)]{8,}[0-9]', '', text)
        
        # ML Feature: Preserve important resume structure
        text = re.sub(r'[^\w\s\.\,\!\\?\-\:\;]', ' ', text)
        
        # Remove extra whitespace but preserve paragraph breaks
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def predict(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ML Prediction: Analyze ATS compatibility with ML scoring and better error handling"""
        try:
            processed_data = self.preprocess(data)
            resume_text = processed_data['resume_text']
            
            if not resume_text:
                return self._get_empty_response()
            
            # ML Feature: Calculate ATS score using weighted components
            ats_score = self._calculate_ml_ats_score(resume_text)
            
            # Apply calibration for more realistic scores
            calibrated_ats_score = self._calibrate_ats_score(ats_score)
            
            # ML Feature: Find ATS issues using pattern recognition
            issues = self._find_ats_issues_ml(resume_text)
            
            # ML Feature: Generate intelligent recommendations
            recommendations = self._generate_ml_recommendations(calibrated_ats_score, issues)
            
            # Return with proper ML model version
            return {
                "ats_score": round(calibrated_ats_score, 4),
                "issues": issues,
                "recommendations": recommendations,
                "model_version": self.get_version()
            }
            
        except Exception as e:
            logger.error(f"ML Error in ATS analysis: {e}")
            return self._get_error_response(str(e))
    
    def _calibrate_ats_score(self, score: float) -> float:
        """Calibrate ATS scores to be more realistic"""
        # Scale up scores to be more in the 0.4-0.9 range for decent resumes
        calibrated = min(score * 1.4, 0.95)  # Scale up but cap at 0.95
        return max(calibrated, 0.2)  # Ensure minimum reasonable score
    
    def _calculate_ml_ats_score(self, resume_text: str) -> float:
        """ML Feature: Calculate ATS score using machine learning principles - CALIBRATED"""
        score = 0.0
        
        # ML Component: Section detection using regex patterns - MORE GENEROUS
        sections_found = self._detect_sections_ml(resume_text)
        section_score = min(len(sections_found) / len(self.section_patterns) * 1.2, 1.0)
        score += section_score * self.weights['sections']
        
        # ML Component: Optimal length scoring - WIDER ACCEPTABLE RANGE
        word_count = len(resume_text.split())
        length_score = self._calculate_length_score_ml(word_count)
        score += length_score * self.weights['length']
        
        # ML Component: Contact information detection - BASE SCORE EVEN IF MISSING
        contact_score = 0.8 if self._has_contact_info_ml(resume_text) else 0.4
        score += contact_score * self.weights['contact']
        
        # ML Component: Achievement quantification - MORE GENEROUS
        achievement_score = min(self._calculate_achievement_score_ml(resume_text) * 1.3, 1.0)
        score += achievement_score * self.weights['achievements']
        
        return min(score, 1.0)
    
    def _detect_sections_ml(self, resume_text: str) -> List[str]:
        """ML Feature: Detect resume sections using pattern matching"""
        found_sections = []
        for section, pattern in self.section_patterns.items():
            if re.search(pattern, resume_text, re.IGNORECASE):
                found_sections.append(section)
        return found_sections
    
    def _calculate_length_score_ml(self, word_count: int) -> float:
        """ML Feature: Calculate optimal resume length score - CALIBRATED"""
        # Based on ATS research but with wider acceptable ranges
        if 350 <= word_count <= 900:  # Optimal range
            return 1.0
        elif 250 <= word_count <= 1200:  # Good range
            return 0.8
        elif 150 <= word_count <= 2000:  # Acceptable range
            return 0.6
        else:
            return 0.3
    
    def _has_contact_info_ml(self, resume_text: str) -> bool:
        """ML Feature: Detect contact information"""
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        return bool(re.search(email_pattern, resume_text))
    
    def _calculate_achievement_score_ml(self, resume_text: str) -> float:
        """ML Feature: Quantify achievement-oriented language - CALIBRATED"""
        achievement_indicators = [
            r'\d+%', r'increased', r'decreased', r'improved', r'reduced',
            r'saved', r'achieved', r'developed', r'managed', r'led'
        ]
        
        indicator_count = 0
        for indicator in achievement_indicators:
            matches = re.findall(indicator, resume_text, re.IGNORECASE)
            indicator_count += len(matches)
        
        # Normalize score based on text length - MORE GENEROUS THRESHOLD
        word_count = len(resume_text.split())
        if word_count == 0:
            return 0.0
        
        density = indicator_count / (word_count / 100)  # per 100 words
        return min(density / 3.0, 1.0)  # More generous: Max 3 indicators per 100 words for full score
    
    def _find_ats_issues_ml(self, resume_text: str) -> List[str]:
        """ML Feature: Intelligent issue detection - CALIBRATED THRESHOLDS"""
        issues = []
        
        # Check sections using ML detection - MORE LENIENT
        sections_found = self._detect_sections_ml(resume_text)
        missing_sections = set(self.section_patterns.keys()) - set(sections_found)
        
        for section in missing_sections:
            issues.append(f"Missing {section.capitalize()} section")
        
        # Check length - WIDER ACCEPTABLE RANGES
        word_count = len(resume_text.split())
        if word_count < 150:  # More lenient minimum
            issues.append("Resume is too short (less than 150 words)")
        elif word_count > 2000:  # More lenient maximum
            issues.append("Resume is too long (more than 2000 words)")
        
        # Check contact info - SUGGESTION INSTEAD OF ERROR
        if not self._has_contact_info_ml(resume_text):
            issues.append("Consider adding professional email address")
        
        # Check achievements - HIGHER THRESHOLD
        achievement_score = self._calculate_achievement_score_ml(resume_text)
        if achievement_score < 0.4:  # Higher threshold
            issues.append("Add more quantifiable achievements and action verbs")
        
        return issues
    
    def _generate_ml_recommendations(self, ats_score: float, issues: List[str]) -> List[str]:
        """ML Feature: Generate intelligent recommendations"""
        recommendations = []
        
        if ats_score < 0.7:  # Adjusted threshold
            recommendations.append("Focus on adding essential sections: Experience, Education, Skills")
        
        if "Consider adding professional email address" in issues:
            recommendations.append("Include a professional email address in contact information")
        
        if "Add more quantifiable achievements" in issues:
            recommendations.append("Use numbers and metrics to quantify achievements (e.g., 'increased efficiency by 25%')")
        
        if ats_score > 0.8:  # Adjusted threshold
            recommendations.append("Good ATS foundation. Consider tailoring for specific job applications")
        elif ats_score > 0.6:  # Adjusted threshold
            recommendations.append("Moderate ATS compatibility. Address the key issues to improve parsing")
        else:
            recommendations.append("Significant improvements needed for ATS compatibility")
        
        return recommendations
    
    def explain(self, prediction: Dict[str, Any]) -> List[str]:
        """ML Feature: Explain the ATS analysis results"""
        explanations = []
        ats_score = prediction.get('ats_score', 0)
        issues = prediction.get('issues', [])
        
        if ats_score >= 0.8:
            explanations.append("Excellent ATS compatibility! High likelihood of passing automated screening.")
        elif ats_score >= 0.6:
            explanations.append("Good ATS compatibility. Minor optimizations can further improve parsing.")
        elif ats_score >= 0.4:
            explanations.append("Moderate ATS compatibility. Several areas need improvement for better parsing.")
        else:
            explanations.append("Poor ATS compatibility. Significant restructuring recommended.")
        
        if issues:
            key_issues = issues[:3]
            explanations.append(f"Priority fixes: {', '.join(key_issues)}")
        
        return explanations
    
    def _get_empty_response(self) -> Dict[str, Any]:
        """ML Error Handling: Empty response"""
        return {
            "ats_score": 0.0,
            "issues": ["No resume text provided for analysis"],
            "recommendations": ["Please provide resume text to analyze ATS compatibility"],
            "model_version": self.get_version()
        }
    
    def _get_error_response(self, error_msg: str) -> Dict[str, Any]:
        """ML Error Handling: Error response with graceful fallback"""
        logger.error(f"ATS model error: {error_msg}")
        return {
            "ats_score": 0.5,  # Neutral fallback
            "issues": ["Temporary analysis issue. Please try again."],
            "recommendations": ["Check your resume format and try the analysis again"],
            "model_version": self.get_version()
        }

# Global ML model instance
ats_model = ATSModel()